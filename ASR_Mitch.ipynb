{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mietsj/Low-resource-language-code/blob/main/ASR_Mitch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zr6ZTbGMOFp"
      },
      "source": [
        "# Automated voice recognission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py5CXCSiEFbC",
        "outputId": "043d49e6-3ee1-4c12-8ebe-172121140000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78nMDZkSNDv6",
        "outputId": "3de76519-ae7c-4d51-a570-43dd88f2783e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20230314.tar.gz (792 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/792.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/792.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.9/792.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (9.1.0)\n",
            "Collecting tiktoken==0.3.1 (from openai-whisper)\n",
            "  Downloading tiktoken-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0 (from openai-whisper)\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2.27.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.12.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (16.0.6)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=796910 sha256=26f01b52cfa816f0738bc664ef5d73c8dad5a432cb5411220ddc6a5c182950f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/13/5f/fe8245f6dc59df505879da4b2129932e342f02a80e6b87f27d\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: ffmpeg-python, tiktoken, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 openai-whisper-20230314 tiktoken-0.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sox\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from sox) (1.22.4)\n",
            "Installing collected packages: sox\n",
            "Successfully installed sox-1.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U openai-whisper\n",
        "!pip install sox\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_fu6n5YJkhZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import whisper\n",
        "import math\n",
        "import re\n",
        "from collections import Counter\n",
        "import string\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_UQyAbjMC7C",
        "outputId": "f16886fb-3ce7-42cb-c38a-2a2ca420d93a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mounting the drive with the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5LxFFdzjH0C",
        "outputId": "03ec8b74-1fb9-459a-da5e-03c73e0c6410"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:01<00:00, 86.1MiB/s]\n"
          ]
        }
      ],
      "source": [
        "#initiating wisper and wisper utility functions\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "def transcribe(model, filename):\n",
        "    res = model.transcribe(filename, fp16=False)\n",
        "    return res[\"text\"]\n",
        "\n",
        "def transcribeLS(model, filename, languageToken):\n",
        "    res = model.transcribe(filename, fp16=False, language=languageToken)\n",
        "    return res[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOUGA-kijvAF"
      },
      "outputs": [],
      "source": [
        "#mitch his scoring stuff\n",
        "def cosinesimularity(vec1, vec2):\n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "    sum1 = sum([vec1[x]**2 for x in list(vec1.keys())])\n",
        "    sum2 = sum([vec2[x]**2 for x in list(vec2.keys())])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return float(numerator) / denominator\n",
        "\n",
        "def text_to_vector(text):\n",
        "    WORD = re.compile(r\"\\w+\")\n",
        "    words = WORD.findall(text)\n",
        "    return Counter(words)\n",
        "\n",
        "def get_cosinesimularity(text1, text2):\n",
        "    vector1 = text_to_vector(text1.lower().translate(str.maketrans('', '', string.punctuation)))\n",
        "    vector2 = text_to_vector(text2.lower().translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "    cosine = cosinesimularity(vector1, vector2)\n",
        "\n",
        "    return cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NACsu8ppXCF"
      },
      "outputs": [],
      "source": [
        "LIMIT = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPbRMxfKV7BA"
      },
      "outputs": [],
      "source": [
        "def grab_keywords(sentence, wlen):\n",
        "    words = sentence.split(\" \")\n",
        "    keywords = []\n",
        "    for i in words:\n",
        "        if len(i) >= wlen:\n",
        "            keywords.append(i)\n",
        "    return \" \".join(keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_sCzuQ7kF0x",
        "outputId": "84b66841-f3c3-4bb9-a22c-d79ba2648cd2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [16:32,  9.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full list: [1.0, 0.9999999999999998, 1.0, 0.0, 1.0, 1.0, 0.8333333333333335, 1.0000000000000002, 0.9999999999999999, 1.0, 0.9999999999999999, 0.8999999999999998, 0.9999999999999998, 1.0, 1.0, 0.9999999999999998, 1.0000000000000002, 0.9999999999999998, 0.9999999999999998, 0.8581163303210331, 0.9999999999999999, 0.9999999999999998, 0.9230769230769232, 0.8432740427115678, 1.0, 0.9999999999999999, 0.8333333333333335, 1.0000000000000002, 0.9999999999999998, 1.0000000000000002, 1.0000000000000002, 0.960768922830523, 0.9999999999999999, 1.0, 0.6708203932499369, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 0.7378647873726218, 0.9999999999999998, 0.9999999999999999, 1.0, 0.8581163303210331, 1.0000000000000002, 1.0, 1.0, 1.0000000000000002, 0.9999999999999998, 1.0, 0.7499999999999999, 1.0, 1.0, 0.9999999999999998, 1.0, 0.9999999999999998, 1.0000000000000002, 0.9999999999999998, 1.0000000000000002, 1.0, 0.8164965809277261, 0.7171371656006361, 1.0, 1.0000000000000002, 0.8249579113843053, 0.9999999999999998, 0.5477225575051661, 0.9999999999999998, 1.0, 0.9999999999999998, 0.9166666666666669, 0.9354143466934852, 0.8666666666666666, 0.9999999999999999, 1.0000000000000002, 1.0000000000000002, 0.9999999999999999, 0.77898083770452, 0.9285714285714286, 0.9999999999999999, 0.8017837257372731, 1.0, 1.0000000000000002, 0.5, 0.9375, 1.0, 1.0000000000000002, 1.0, 0.8333333333333335, 0.8333333333333335, 0.9999999999999998, 0.917662935482247, 0.0, 1.0000000000000002, 0.9333333333333332, 0.8749999999999998, 1.0000000000000002, 0.9999999999999998, 0.9999999999999999]\n",
            "The english average accuracy: 0.9304235612858132\n",
            "The english keyword spotting accuracy: 0.8239163995939388\n",
            "Full list LS: [1.0, 0.9999999999999998, 1.0, 1.0, 1.0, 1.0, 0.8333333333333335, 1.0000000000000002, 0.9999999999999999, 1.0, 0.9999999999999999, 0.8999999999999998, 0.9999999999999998, 1.0, 1.0, 0.9999999999999998, 1.0000000000000002, 0.9999999999999998, 0.9999999999999998, 0.8581163303210331, 0.9999999999999999, 0.9999999999999998, 0.9230769230769232, 0.8432740427115678, 1.0, 0.9999999999999999, 0.8333333333333335, 1.0000000000000002, 0.9999999999999998, 1.0000000000000002, 1.0000000000000002, 0.960768922830523, 0.9999999999999999, 1.0, 0.6708203932499369, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 0.7378647873726218, 0.9999999999999998, 0.9999999999999999, 1.0, 0.8581163303210331, 1.0000000000000002, 1.0, 1.0, 1.0000000000000002, 0.9999999999999998, 1.0, 0.7499999999999999, 1.0, 1.0, 0.9999999999999998, 1.0, 0.9999999999999998, 1.0000000000000002, 0.9999999999999998, 1.0000000000000002, 1.0, 0.8164965809277261, 0.7171371656006361, 1.0, 1.0000000000000002, 0.8249579113843053, 0.9999999999999998, 0.5477225575051661, 0.9999999999999998, 1.0, 0.9999999999999998, 0.9166666666666669, 0.9354143466934852, 0.8666666666666666, 0.9999999999999999, 1.0000000000000002, 1.0000000000000002, 0.9999999999999999, 0.77898083770452, 0.9285714285714286, 0.9999999999999999, 0.8017837257372731, 1.0, 1.0000000000000002, 0.5, 0.9375, 1.0, 1.0000000000000002, 1.0, 0.8333333333333335, 0.8333333333333335, 0.9999999999999998, 0.917662935482247, 1.0, 1.0000000000000002, 0.9333333333333332, 0.8749999999999998, 1.0000000000000002, 0.9999999999999998, 0.9999999999999999]\n",
            "The english average accuracy LS: 0.9504235612858132\n",
            "The english keyword spotting accuracy LS: 0.8428606715039381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Establish baseline with english test\n",
        "#loading in the dataset csv\n",
        "dataEnglish = pd.read_csv(\"/content/drive/MyDrive/cv-valid-test.csv\")\n",
        "AccList = []\n",
        "AccListLS = []\n",
        "KeyWordAcc = []\n",
        "KeyWordAccLS = []\n",
        "i = 0\n",
        "\n",
        "for samp in tqdm(dataEnglish.iterrows()):\n",
        "  if i == LIMIT:\n",
        "    break\n",
        "  file_path = \"/content/drive/MyDrive/\"+samp[1][0]\n",
        "  pred = transcribe(model, file_path)\n",
        "  predLS = transcribeLS(model, file_path, \"en\")\n",
        "  text = samp[1][1]\n",
        "  AccList.append(get_cosinesimularity(pred,text))\n",
        "  AccListLS.append(get_cosinesimularity(predLS,text))\n",
        "  KeyWordAcc.append(get_cosinesimularity(grab_keywords(pred ,5), grab_keywords(text, 5)))\n",
        "  KeyWordAccLS.append(get_cosinesimularity(grab_keywords(predLS ,5), grab_keywords(text, 5)))\n",
        "  i = i + 1\n",
        "Average = sum(AccList) / len(AccList)\n",
        "print(\"Full list: \" + str(AccList))\n",
        "print(\"The english average accuracy: \" + str(Average))\n",
        "print(\"The english keyword spotting accuracy: \" + str(sum(KeyWordAcc)/len(KeyWordAcc)))\n",
        "\n",
        "AverageLS = sum(AccListLS) / len(AccListLS)\n",
        "print(\"Full list LS: \" + str(AccListLS))\n",
        "print(\"The english average accuracy LS: \" + str(AverageLS))\n",
        "print(\"The english keyword spotting accuracy LS: \" + str(sum(KeyWordAccLS)/len(KeyWordAccLS)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z71sfs1JhLG7",
        "outputId": "e9e00b63-037f-41c5-d4a2-007e477530a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [1:59:38, 71.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full list: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "The armenian average accuracy: 0.0\n",
            "The armenian keyword spotting accuracy: 0.0\n",
            "Full list LS: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "The armenian average accuracy LS: 0.0\n",
            "The armenian keyword spotting accuracy LS: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Establish baseline with Armenian test\n",
        "#loading in the dataset tsv\n",
        "dataArmenian = pd.read_csv(\"/content/drive/MyDrive/CommonVoiceMitch/Armenian/hy-AM/validated.tsv\", sep=\"\\t\")\n",
        "AccList = []\n",
        "AccListLS = []\n",
        "KeyWordAcc = []\n",
        "KeyWordAccLS = []\n",
        "i = 0\n",
        "\n",
        "for samp in tqdm(dataArmenian.iterrows()):\n",
        "  if i == LIMIT:\n",
        "    break\n",
        "  file_path = \"/content/drive/MyDrive/CommonVoiceMitch/Armenian/hy-AM/clips/\"+samp[1][1]\n",
        "  pred = transcribe(model, file_path)\n",
        "  predLS = transcribeLS(model, file_path, \"hy\")\n",
        "  text = samp[1][2]\n",
        "  AccList.append(get_cosinesimularity(pred,text))\n",
        "  AccListLS.append(get_cosinesimularity(predLS,text))\n",
        "  KeyWordAcc.append(get_cosinesimularity(grab_keywords(pred ,5), grab_keywords(text, 5)))\n",
        "  KeyWordAccLS.append(get_cosinesimularity(grab_keywords(predLS ,5), grab_keywords(text, 5)))\n",
        "  i = i + 1\n",
        "Average = sum(AccList) / len(AccList)\n",
        "print(\"Full list: \" + str(AccList))\n",
        "print(\"The armenian average accuracy: \" + str(Average))\n",
        "print(\"The armenian keyword spotting accuracy: \" + str(sum(KeyWordAcc)/len(KeyWordAcc)))\n",
        "\n",
        "AverageLS = sum(AccListLS) / len(AccListLS)\n",
        "print(\"Full list LS: \" + str(AccListLS))\n",
        "print(\"The armenian average accuracy LS: \" + str(AverageLS))\n",
        "print(\"The armenian keyword spotting accuracy LS: \" + str(sum(KeyWordAccLS)/len(KeyWordAccLS)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK50hvBuo6Wx",
        "outputId": "85692742-91c9-469d-8f47-1577716fd124"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "87it [22:54, 15.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full list: [0.25087260300212727, 0.0, 0.08770580193070293, 0.0, 0.07692307692307693, 0.33333333333333337, 0.0, 0.0, 0.09534625892455924, 0.21081851067789195, 0.12499999999999997, 0.0, 0.0, 0.0, 0.33333333333333337, 0.35856858280031806, 0.08006407690254358, 0.38138503569823695, 0.5222329678670935, 0.3086066999241838, 0.0, 0.2857142857142857, 0.25087260300212727, 0.37573457465108967, 0.08451542547285165, 0.09622504486493763, 0.40089186286863654, 0.0, 0.0, 0.33333333333333337, 0.0, 0.16666666666666669, 0.0, 0.15384615384615385, 0.19999999999999996, 0.15384615384615385, 0.22237479499833038, 0.1336306209562122, 0.2307692307692308, 0.13363062095621217, 0.0, 0.13363062095621217, 0.0, 0.0, 0.0, 0.24019223070763074, 0.0, 0.09534625892455924, 0.08058229640253803, 0.0, 0.2307692307692308, 0.2519763153394848, 0.0, 0.14285714285714285, 0.0, 0.0, 0.35355339059327373, 0.4472135954999579, 0.3999999999999999, 0.4803844614152615, 0.2727272727272727, 0.0, 0.0, 0.10341753799900383, 0.0, 0.10540925533894598, 0.0, 0.0, 0.0, 0.0, 0.4743416490252569, 0.4285714285714285, 0.1543033499620919, 0.22360679774997896, 0.0, 0.14285714285714285, 0.33806170189140655, 0.0, 0.16666666666666669, 0.20412414523193154, 0.23904572186687872, 0.33333333333333337, 0.75, 0.0, 0.0, 0.0, 0.2886751345948129]\n",
            "The azerbaijani average accuracy: 0.15480331419017318\n",
            "The azerbaijani keyword spotting accuracy: 0.13244757870164917\n",
            "Full list LS: [0.19069251784911848, 0.0, 0.0, 0.33333333333333337, 0.24019223070763074, 0.33333333333333337, 0.0, 0.09622504486493763, 0.19069251784911848, 0.21081851067789195, 0.12499999999999997, 0.5345224838248487, 0.25, 0.0, 0.33333333333333337, 0.3086066999241838, 0.08333333333333334, 0.8181818181818182, 0.5000000000000001, 0.40089186286863654, 0.4999999999999999, 0.2857142857142857, 0.36363636363636365, 0.29814239699997197, 0.09999999999999998, 0.2222222222222222, 0.5714285714285714, 0.18257418583505536, 0.12499999999999997, 0.16666666666666669, 0.0, 0.16666666666666669, 0.0, 0.14824986333222026, 0.19999999999999996, 0.16012815380508716, 0.3086066999241839, 0.3223291856101521, 0.25087260300212727, 0.0, 0.0, 0.11952286093343936, 0.0, 0.33333333333333337, 0.0, 0.24019223070763074, 0.1178511301977579, 0.28603877677367767, 0.14824986333222026, 0.1543033499620919, 0.44474958999666075, 0.3779644730092272, 0.0, 0.14285714285714285, 0.0, 0.0, 0.35355339059327373, 0.4472135954999579, 0.5999999999999999, 0.3849001794597505, 0.2727272727272727, 0.0, 0.0, 0.06482037235521644, 0.0, 0.09999999999999998, 0.19999999999999996, 0.14433756729740646, 0.0, 0.0, 0.7499999999999999, 0.4285714285714285, 0.33333333333333337, 0.4472135954999579, 0.0, 0.3086066999241838, 0.3086066999241838, 0.0, 0.3651483716701107, 0.4082482904638631, 0.14285714285714285, 0.33333333333333337, 1.0, 0.0, 0.0, 0.19999999999999996, 0.33333333333333337]\n",
            "The azerbaijani average accuracy LS: 0.22543979589508062\n",
            "The azerbaijani keyword spotting accuracy LS: 0.20208341227595142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Establish baseline with Azerbaijani test\n",
        "#loading in the dataset tsv\n",
        "dataAzerbaijani = pd.read_csv(\"/content/drive/MyDrive/CommonVoiceMitch/Azerbaijani/az/validated.tsv\", sep=\"\\t\")\n",
        "AccList = []\n",
        "AccListLS = []\n",
        "KeyWordAcc = []\n",
        "KeyWordAccLS = []\n",
        "i = 0\n",
        "\n",
        "for samp in tqdm(dataAzerbaijani.iterrows()):\n",
        "  if i == LIMIT:\n",
        "    break\n",
        "  file_path = \"/content/drive/MyDrive/CommonVoiceMitch/Azerbaijani/az/clips/\"+samp[1][1]\n",
        "  pred = transcribe(model, file_path)\n",
        "  predLS = transcribeLS(model, file_path, \"az\")\n",
        "  text = samp[1][2]\n",
        "  AccList.append(get_cosinesimularity(pred,text))\n",
        "  AccListLS.append(get_cosinesimularity(predLS,text))\n",
        "  KeyWordAcc.append(get_cosinesimularity(grab_keywords(pred ,5), grab_keywords(text, 5)))\n",
        "  KeyWordAccLS.append(get_cosinesimularity(grab_keywords(predLS ,5), grab_keywords(text, 5)))\n",
        "  i = i + 1\n",
        "Average = sum(AccList) / len(AccList)\n",
        "print(\"Full list: \" + str(AccList))\n",
        "print(\"The azerbaijani average accuracy: \" + str(Average))\n",
        "print(\"The azerbaijani keyword spotting accuracy: \" + str(sum(KeyWordAcc)/len(KeyWordAcc)))\n",
        "\n",
        "AverageLS = sum(AccListLS) / len(AccListLS)\n",
        "print(\"Full list LS: \" + str(AccListLS))\n",
        "print(\"The azerbaijani average accuracy LS: \" + str(AverageLS))\n",
        "print(\"The azerbaijani keyword spotting accuracy LS: \" + str(sum(KeyWordAccLS)/len(KeyWordAccLS)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIk3E6QJqOGN",
        "outputId": "94051b47-c357-4d6b-a950-b4e3ae3abcc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10it [07:09, 42.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full list: [0.0, 0.0, 0.0, 0.0, 0.09128709291752768, 0.0, 0.24999999999999994, 0.0, 0.09622504486493763, 0.0]\n",
            "The icelandic average accuracy: 0.04375121377824652\n",
            "The icelandic keyword spotting accuracy: 0.015430334996209192\n",
            "Full list LS: [0.12433397443204185, 0.23570226039551587, 0.0, 0.08703882797784893, 0.08703882797784893, 0.0, 0.13363062095621217, 0.0, 0.08703882797784893, 0.0]\n",
            "The icelandic average accuracy LS: 0.07547833397173166\n",
            "The icelandic keyword spotting accuracy LS: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Establish baseline with Icelandic test\n",
        "#loading in the dataset tsv\n",
        "dataIcelandic = pd.read_csv(\"/content/drive/MyDrive/CommonVoiceMitch/Icelandic/is/other.tsv\", sep=\"\\t\")\n",
        "AccList = []\n",
        "AccListLS = []\n",
        "KeyWordAcc = []\n",
        "KeyWordAccLS = []\n",
        "i = 0\n",
        "\n",
        "for samp in tqdm(dataIcelandic.iterrows()):\n",
        "  if i == LIMIT:\n",
        "    break\n",
        "  file_path = \"/content/drive/MyDrive/CommonVoiceMitch/Icelandic/is/clips/\"+samp[1][1]\n",
        "  pred = transcribe(model, file_path)\n",
        "  predLS = transcribeLS(model, file_path, \"is\")\n",
        "  text = samp[1][2]\n",
        "  AccList.append(get_cosinesimularity(pred,text))\n",
        "  AccListLS.append(get_cosinesimularity(predLS,text))\n",
        "  KeyWordAcc.append(get_cosinesimularity(grab_keywords(pred ,5), grab_keywords(text, 5)))\n",
        "  KeyWordAccLS.append(get_cosinesimularity(grab_keywords(predLS ,5), grab_keywords(text, 5)))\n",
        "  i = i + 1\n",
        "Average = sum(AccList) / len(AccList)\n",
        "print(\"Full list: \" + str(AccList))\n",
        "print(\"The icelandic average accuracy: \" + str(Average))\n",
        "print(\"The icelandic keyword spotting accuracy: \" + str(sum(KeyWordAcc)/len(KeyWordAcc)))\n",
        "\n",
        "AverageLS = sum(AccListLS) / len(AccListLS)\n",
        "print(\"Full list LS: \" + str(AccListLS))\n",
        "print(\"The icelandic average accuracy LS: \" + str(AverageLS))\n",
        "print(\"The icelandic keyword spotting accuracy LS: \" + str(sum(KeyWordAccLS)/len(KeyWordAccLS)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zom7yWa8q1D4",
        "outputId": "9d5b1312-2743-4e26-e9ce-cc21dc9d9312"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [38:17, 22.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full list: [0.0, 0.0, 0.0, 0.15811388300841897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0816496580927726, 0.0, 0.0, 0.14142135623730948, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09128709291752767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20412414523193148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2357022603955158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "The kazakh average accuracy: 0.011980126815977616\n",
            "The kazakh keyword spotting accuracy: 0.0065042749475954405\n",
            "Full list LS: [0.0, 0.0, 0.6249999999999999, 0.0, 0.0, 0.0, 0.0, 0.1432229748078866, 0.0, 0.0, 0.0, 0.18257418583505536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.19999999999999996, 0.35355339059327373, 0.0, 0.0, 0.1178511301977579, 0.0, 0.0, 0.0, 0.0, 0.20412414523193148, 0.0, 0.0, 0.0, 0.5000000000000001, 0.19999999999999996, 0.17677669529663687, 0.0, 0.0816496580927726, 0.0, 0.0, 0.14142135623730948, 0.0, 0.0, 0.0, 0.12909944487358058, 0.0, 0.0, 0.0, 0.10206207261596574, 0.5270462766947299, 0.20412414523193154, 0.5000000000000001, 0.09128709291752767, 0.0, 0.18257418583505536, 0.0, 0.0, 0.09999999999999998, 0.10660035817780521, 0.0, 0.0, 0.20412414523193148, 0.0, 0.0, 0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 0.0, 0.22360679774997896, 0.19999999999999996, 0.43301270189221935, 0.22360679774997896, 0.5000000000000001, 0.0, 0.0, 0.0, 0.6666666666666667, 0.2357022603955158, 0.0, 0.0, 0.0, 0.0, 0.2519763153394848, 0.20412414523193154, 0.0, 0.0, 0.0, 0.06537204504606135, 0.25, 0.0, 0.1543033499620919, 0.5714285714285714, 0.0, 0.33333333333333337, 0.0, 0.0]\n",
            "The kazakh average accuracy LS: 0.09838605195047939\n",
            "The kazakh keyword spotting accuracy LS: 0.0703591090459582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Establish baseline with Kazakh test\n",
        "#loading in the dataset tsv\n",
        "dataKazakh = pd.read_csv(\"/content/drive/MyDrive/CommonVoiceMitch/Kazakh/kk/validated.tsv\", sep=\"\\t\")\n",
        "AccList = []\n",
        "AccListLS = []\n",
        "KeyWordAcc = []\n",
        "KeyWordAccLS = []\n",
        "i = 0\n",
        "\n",
        "for samp in tqdm(dataKazakh.iterrows()):\n",
        "  if i == LIMIT:\n",
        "    break\n",
        "  file_path = \"/content/drive/MyDrive/CommonVoiceMitch/Kazakh/kk/clips/\"+samp[1][1]\n",
        "  pred = transcribe(model, file_path)\n",
        "  predLS = transcribeLS(model, file_path, \"kk\")\n",
        "  text = samp[1][2]\n",
        "  AccList.append(get_cosinesimularity(pred,text))\n",
        "  AccListLS.append(get_cosinesimularity(predLS,text))\n",
        "  KeyWordAcc.append(get_cosinesimularity(grab_keywords(pred ,5), grab_keywords(text, 5)))\n",
        "  KeyWordAccLS.append(get_cosinesimularity(grab_keywords(predLS ,5), grab_keywords(text, 5)))\n",
        "  i = i + 1\n",
        "Average = sum(AccList) / len(AccList)\n",
        "print(\"Full list: \" + str(AccList))\n",
        "print(\"The kazakh average accuracy: \" + str(Average))\n",
        "print(\"The kazakh keyword spotting accuracy: \" + str(sum(KeyWordAcc)/len(KeyWordAcc)))\n",
        "\n",
        "AverageLS = sum(AccListLS) / len(AccListLS)\n",
        "print(\"Full list LS: \" + str(AccListLS))\n",
        "print(\"The kazakh average accuracy LS: \" + str(AverageLS))\n",
        "print(\"The kazakh keyword spotting accuracy LS: \" + str(sum(KeyWordAccLS)/len(KeyWordAccLS)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xwqt-FXrOLd",
        "outputId": "3904dc4c-8d38-4416-8eab-3c4d6b143f17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [17:19, 10.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full list: [0.9258200997725514, 0.6943650748294137, 0.6172133998483676, 0.6249999999999999, 0.7142857142857142, 1.0000000000000002, 0.38138503569823695, 0.6666666666666666, 0.4803844614152615, 0.6324555320336759, 0.5999999999999999, 0.9999999999999999, 0.4472135954999579, 0.5892556509887895, 0.5892556509887895, 0.0, 0.5714285714285714, 0.857142857142857, 0.2581988897471611, 0.7833494518006403, 0.7999999999999998, 0.857142857142857, 0.8432740427115678, 0.6708203932499369, 0.37499999999999994, 1.0000000000000002, 0.6324555320336759, 0.3086066999241838, 0.16666666666666669, 1.0, 0.6666666666666667, 0.33806170189140655, 0.6249999999999999, 0.19999999999999996, 0.75, 0.3999999999999999, 0.4714045207910316, 0.6249999999999999, 0.7627700713964739, 0.18181818181818182, 0.6249999999999999, 0.5000000000000001, 0.2721655269759087, 0.13608276348795434, 0.8333333333333335, 0.75, 0.75, 0.0, 0.6172133998483676, 0.5555555555555556, 0.5555555555555556, 1.0000000000000002, 0.0, 0.6363636363636364, 0.5833333333333334, 0.0, 0.5000000000000001, 0.9090909090909091, 1.0000000000000002, 0.8749999999999998, 0.6249999999999999, 0.9999999999999998, 0.6172133998483676, 0.9999999999999998, 0.7302967433402214, 0.7378647873726218, 0.6666666666666666, 0.8749999999999998, 0.6674238124719146, 0.4767312946227962, 0.5477225575051661, 0.5892556509887895, 0.5477225575051661, 1.0000000000000002, 0.7715167498104595, 0.7999999999999998, 0.7777777777777778, 0.7833494518006403, 0.47809144373375745, 0.26726124191242434, 0.8333333333333335, 0.6735753140545634, 0.5773502691896258, 0.5892556509887895, 0.5999999999999999, 1.0, 0.4767312946227962, 0.5345224838248487, 0.7499999999999999, 0.4999999999999999, 0.7999999999999998, 0.5, 0.4216370213557839, 0.7302967433402214, 0.5892556509887895, 0.5714285714285714, 0.33333333333333337, 0.3333333333333333, 0.2357022603955158, 0.7272727272727273]\n",
            "The korean average accuracy: 0.6094272412280286\n",
            "The korean keyword spotting accuracy: 0.29553154203903303\n",
            "Full list LS: [0.9258200997725514, 0.6943650748294137, 0.6172133998483676, 0.6249999999999999, 0.7142857142857142, 1.0000000000000002, 0.38138503569823695, 0.6666666666666666, 0.4803844614152615, 0.6324555320336759, 0.5999999999999999, 0.9999999999999999, 0.4472135954999579, 0.5892556509887895, 0.5892556509887895, 1.0000000000000002, 0.5714285714285714, 0.857142857142857, 0.2581988897471611, 0.7833494518006403, 0.7999999999999998, 0.857142857142857, 0.8432740427115678, 0.6708203932499369, 0.37499999999999994, 1.0000000000000002, 0.6324555320336759, 0.3086066999241838, 0.16666666666666669, 1.0, 0.6666666666666667, 0.33806170189140655, 0.6249999999999999, 0.19999999999999996, 0.75, 0.3999999999999999, 0.4714045207910316, 0.6249999999999999, 0.7627700713964739, 0.18181818181818182, 0.6249999999999999, 0.5000000000000001, 0.2721655269759087, 0.13608276348795434, 0.8333333333333335, 0.75, 0.75, 0.0, 0.6172133998483676, 0.5555555555555556, 0.5555555555555556, 1.0000000000000002, 0.0, 0.6363636363636364, 0.5833333333333334, 0.40824829046386296, 0.5000000000000001, 0.9090909090909091, 1.0000000000000002, 0.8749999999999998, 0.6249999999999999, 0.9999999999999998, 0.6172133998483676, 0.9999999999999998, 0.7302967433402214, 0.7378647873726218, 0.6666666666666666, 0.8749999999999998, 0.6674238124719146, 0.4767312946227962, 0.5477225575051661, 0.5892556509887895, 0.5477225575051661, 1.0000000000000002, 0.7715167498104595, 0.7999999999999998, 0.7777777777777778, 0.7833494518006403, 0.47809144373375745, 0.26726124191242434, 0.8333333333333335, 0.6735753140545634, 0.5773502691896258, 0.5892556509887895, 0.5999999999999999, 1.0, 0.4767312946227962, 0.5345224838248487, 0.7499999999999999, 0.4999999999999999, 0.7999999999999998, 0.5, 0.4216370213557839, 0.7302967433402214, 0.5892556509887895, 0.5714285714285714, 0.33333333333333337, 0.3333333333333333, 0.2357022603955158, 0.7272727272727273]\n",
            "The korean average accuracy LS: 0.6235097241326671\n",
            "The korean keyword spotting accuracy LS: 0.29553154203903303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Establish baseline with Korean test\n",
        "#loading in the dataset tsv\n",
        "dataKorean = pd.read_csv(\"/content/drive/MyDrive/CommonVoiceMitch/Korean/ko/validated.tsv\", sep=\"\\t\")\n",
        "AccList = []\n",
        "AccListLS = []\n",
        "KeyWordAcc = []\n",
        "KeyWordAccLS = []\n",
        "i = 0\n",
        "\n",
        "for samp in tqdm(dataKorean.iterrows()):\n",
        "  if i == LIMIT:\n",
        "    break\n",
        "  file_path = \"/content/drive/MyDrive/CommonVoiceMitch/Korean/ko/clips/\"+samp[1][1]\n",
        "  pred = transcribe(model, file_path)\n",
        "  predLS = transcribeLS(model, file_path, \"ko\")\n",
        "  text = samp[1][2]\n",
        "  AccList.append(get_cosinesimularity(pred,text))\n",
        "  AccListLS.append(get_cosinesimularity(predLS,text))\n",
        "  KeyWordAcc.append(get_cosinesimularity(grab_keywords(pred ,5), grab_keywords(text, 5)))\n",
        "  KeyWordAccLS.append(get_cosinesimularity(grab_keywords(predLS ,5), grab_keywords(text, 5)))\n",
        "  i = i + 1\n",
        "Average = sum(AccList) / len(AccList)\n",
        "print(\"Full list: \" + str(AccList))\n",
        "print(\"The korean average accuracy: \" + str(Average))\n",
        "print(\"The korean keyword spotting accuracy: \" + str(sum(KeyWordAcc)/len(KeyWordAcc)))\n",
        "\n",
        "AverageLS = sum(AccListLS) / len(AccListLS)\n",
        "print(\"Full list LS: \" + str(AccListLS))\n",
        "print(\"The korean average accuracy LS: \" + str(AverageLS))\n",
        "print(\"The korean keyword spotting accuracy LS: \" + str(sum(KeyWordAccLS)/len(KeyWordAccLS)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYrMheh1rkf_",
        "outputId": "94cb5693-d3dc-47ee-af3d-a7a5b3d82c3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [21:33, 12.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full list: [0.0, 0.4714045207910316, 0.16116459280507606, 0.0, 0.22360679774997896, 0.0, 0.22613350843332272, 0.6030226891555273, 0.5222329678670935, 0.4285714285714285, 0.4708709557974188, 0.7142857142857142, 0.4714045207910316, 0.0, 0.0, 0.0, 0.23145502494313788, 0.0, 0.0, 0.18181818181818182, 0.08058229640253803, 0.0, 0.6092717958449424, 0.36084391824351614, 0.0, 0.0, 0.0, 0.26111648393354675, 0.0, 0.0, 0.3651483716701107, 0.0, 0.0, 0.3481553119113957, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5270462766947299, 0.0, 0.6324555320336759, 0.48666426339228763, 0.0, 0.17928429140015903, 0.0, 0.10660035817780521, 0.10540925533894598, 0.22360679774997896, 0.0, 0.4629100498862757, 0.0, 0.36514837167011077, 0.0, 0.0, 0.0, 0.26906911759852503, 0.0, 0.0, 0.4714045207910316, 0.0, 0.17541160386140586, 0.0, 0.0, 0.0, 0.0, 0.09128709291752768, 0.13363062095621217, 0.45226701686664544, 0.6249999999999999, 0.1178511301977579, 0.08006407690254358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4216370213557839, 0.2727272727272727, 0.0, 0.0, 0.3999999999999999, 0.2857142857142857, 0.3333333333333333, 0.0, 0.0, 0.0, 0.43876345447627835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06900655593423542, 0.41666666666666674, 0.0]\n",
            "The macedonian average accuracy: 0.14874048047658467\n",
            "The macedonian keyword spotting accuracy: 0.10952666690720257\n",
            "Full list LS: [0.15811388300841897, 0.35355339059327373, 0.15430334996209194, 0.6471502289294341, 0.5, 0.0, 0.43301270189221935, 0.7627700713964739, 0.4351941398892446, 0.5714285714285714, 0.5188745216627709, 0.7142857142857142, 0.4714045207910316, 0.2857142857142857, 0.6288281455225324, 0.31622776601683794, 0.3086066999241839, 0.5270462766947299, 0.4472135954999579, 0.09534625892455924, 0.2760262237369417, 0.45454545454545453, 0.5222329678670935, 0.5051814855409226, 0.35714285714285715, 0.0, 0.5070925528371099, 0.2886751345948129, 0.38138503569823695, 0.4285714285714285, 0.3651483716701107, 0.22360679774997896, 0.5892556509887895, 0.46291004988627577, 0.26726124191242434, 0.3344968040028363, 0.5270462766947299, 0.45643546458763845, 0.2886751345948129, 0.7777777777777778, 0.09245003270420486, 0.4216370213557839, 0.669438681395203, 0.21320071635561041, 0.3241018617760822, 0.33541019662496846, 0.30151134457776363, 0.10540925533894598, 0.6674238124719146, 0.0, 0.5714285714285714, 0.4999999999999999, 0.5773502691896257, 0.0, 0.31622776601683794, 1.0, 0.2773500981126146, 0.20412414523193154, 0.3849001794597505, 0.26726124191242434, 0.2581988897471611, 0.17541160386140586, 0.1543033499620919, 0.19069251784911848, 0.13363062095621217, 0.6681531047810609, 0.29999999999999993, 0.12499999999999997, 0.5640760748177662, 0.6249999999999999, 0.4444444444444444, 0.3344968040028363, 0.2519763153394848, 0.0, 0.2666666666666666, 0.41812100500354543, 0.27386127875258304, 0.5270462766947299, 0.5720775535473553, 0.1259881576697424, 0.20412414523193154, 0.33806170189140655, 0.4285714285714285, 0.31622776601683794, 0.0, 0.2795084971874737, 0.0, 0.3223291856101521, 0.26726124191242434, 0.37499999999999994, 0.20412414523193154, 0.27386127875258304, 0.0, 0.5000000000000001, 0.0, 0.11396057645963795, 0.25, 0.07715167498104597, 0.5833333333333334, 0.0]\n",
            "The macedonian average accuracy LS: 0.3451442566576518\n",
            "The macedonian keyword spotting accuracy LS: 0.25393947294717734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Establish baseline with Macedonian test\n",
        "#loading in the dataset tsv\n",
        "dataMacedonian = pd.read_csv(\"/content/drive/MyDrive/CommonVoiceMitch/Macedonian/mk/validated.tsv\", sep=\"\\t\")\n",
        "AccList = []\n",
        "AccListLS = []\n",
        "KeyWordAcc = []\n",
        "KeyWordAccLS = []\n",
        "i = 0\n",
        "\n",
        "for samp in tqdm(dataMacedonian.iterrows()):\n",
        "  if i == LIMIT:\n",
        "    break\n",
        "  file_path = \"/content/drive/MyDrive/CommonVoiceMitch/Macedonian/mk/clips/\"+samp[1][1]\n",
        "  pred = transcribe(model, file_path)\n",
        "  predLS = transcribeLS(model, file_path, \"mk\")\n",
        "  text = samp[1][2]\n",
        "  AccList.append(get_cosinesimularity(pred,text))\n",
        "  AccListLS.append(get_cosinesimularity(predLS,text))\n",
        "  KeyWordAcc.append(get_cosinesimularity(grab_keywords(pred ,5), grab_keywords(text, 5)))\n",
        "  KeyWordAccLS.append(get_cosinesimularity(grab_keywords(predLS ,5), grab_keywords(text, 5)))\n",
        "  i = i + 1\n",
        "Average = sum(AccList) / len(AccList)\n",
        "print(\"Full list: \" + str(AccList))\n",
        "print(\"The macedonian average accuracy: \" + str(Average))\n",
        "print(\"The macedonian keyword spotting accuracy: \" + str(sum(KeyWordAcc)/len(KeyWordAcc)))\n",
        "\n",
        "AverageLS = sum(AccListLS) / len(AccListLS)\n",
        "print(\"Full list LS: \" + str(AccListLS))\n",
        "print(\"The macedonian average accuracy LS: \" + str(AverageLS))\n",
        "print(\"The macedonian keyword spotting accuracy LS: \" + str(sum(KeyWordAccLS)/len(KeyWordAccLS)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8s6uoCzr7me",
        "outputId": "eb628da9-2ec2-4a8b-ff10-515f1d3cfc8f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [45:15, 27.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full list: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "The malay average accuracy: 0.0\n",
            "The malay keyword spotting accuracy: 0.0\n",
            "Full list LS: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "The malay average accuracy LS: 0.0\n",
            "The malay keyword spotting accuracy LS: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Establish baseline with Malay test\n",
        "#loading in the dataset tsv\n",
        "dataMalay = pd.read_csv(\"/content/drive/MyDrive/CommonVoiceMitch/Malay/ml/validated.tsv\", sep=\"\\t\")\n",
        "AccList = []\n",
        "AccListLS = []\n",
        "KeyWordAcc = []\n",
        "KeyWordAccLS = []\n",
        "i = 0\n",
        "\n",
        "for samp in tqdm(dataMalay.iterrows()):\n",
        "  if i == LIMIT:\n",
        "    break\n",
        "  file_path = \"/content/drive/MyDrive/CommonVoiceMitch/Malay/ml/clips/\"+samp[1][1]\n",
        "  pred = transcribe(model, file_path)\n",
        "  predLS = transcribeLS(model, file_path, \"ml\")\n",
        "  text = samp[1][2]\n",
        "  AccList.append(get_cosinesimularity(pred,text))\n",
        "  AccListLS.append(get_cosinesimularity(predLS,text))\n",
        "  KeyWordAcc.append(get_cosinesimularity(grab_keywords(pred ,5), grab_keywords(text, 5)))\n",
        "  KeyWordAccLS.append(get_cosinesimularity(grab_keywords(predLS ,5), grab_keywords(text, 5)))\n",
        "  i = i + 1\n",
        "Average = sum(AccList) / len(AccList)\n",
        "print(\"Full list: \" + str(AccList))\n",
        "print(\"The malay average accuracy: \" + str(Average))\n",
        "print(\"The malay keyword spotting accuracy: \" + str(sum(KeyWordAcc)/len(KeyWordAcc)))\n",
        "\n",
        "AverageLS = sum(AccListLS) / len(AccListLS)\n",
        "print(\"Full list LS: \" + str(AccListLS))\n",
        "print(\"The malay average accuracy LS: \" + str(AverageLS))\n",
        "print(\"The malay keyword spotting accuracy LS: \" + str(sum(KeyWordAccLS)/len(KeyWordAccLS)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyMa0QrlsNK2",
        "outputId": "18efdf47-3c33-46b0-f3a6-105a11216573"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [33:12, 19.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full list: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "The nepali average accuracy: 0.0\n",
            "The nepali keyword spotting accuracy: 0.0\n",
            "Full list LS: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "The nepali average accuracy LS: 0.0\n",
            "The nepali keyword spotting accuracy LS: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Establish baseline with Nepali test\n",
        "#loading in the dataset tsv\n",
        "dataNepali = pd.read_csv(\"/content/drive/MyDrive/CommonVoiceMitch/Nepali/ne-NP/validated.tsv\", sep=\"\\t\")\n",
        "AccList = []\n",
        "AccListLS = []\n",
        "KeyWordAcc = []\n",
        "KeyWordAccLS = []\n",
        "i = 0\n",
        "\n",
        "for samp in tqdm(dataNepali.iterrows()):\n",
        "  if i == LIMIT:\n",
        "    break\n",
        "  file_path = \"/content/drive/MyDrive/CommonVoiceMitch/Nepali/ne-NP/clips/\"+samp[1][1]\n",
        "  pred = transcribe(model, file_path)\n",
        "  predLS = transcribeLS(model, file_path, \"ne\")\n",
        "  text = samp[1][2]\n",
        "  AccList.append(get_cosinesimularity(pred,text))\n",
        "  AccListLS.append(get_cosinesimularity(predLS,text))\n",
        "  KeyWordAcc.append(get_cosinesimularity(grab_keywords(pred ,5), grab_keywords(text, 5)))\n",
        "  KeyWordAccLS.append(get_cosinesimularity(grab_keywords(predLS ,5), grab_keywords(text, 5)))\n",
        "  i = i + 1\n",
        "Average = sum(AccList) / len(AccList)\n",
        "print(\"Full list: \" + str(AccList))\n",
        "print(\"The nepali average accuracy: \" + str(Average))\n",
        "print(\"The nepali keyword spotting accuracy: \" + str(sum(KeyWordAcc)/len(KeyWordAcc)))\n",
        "\n",
        "AverageLS = sum(AccListLS) / len(AccListLS)\n",
        "print(\"Full list LS: \" + str(AccListLS))\n",
        "print(\"The nepali average accuracy LS: \" + str(AverageLS))\n",
        "print(\"The nepali keyword spotting accuracy LS: \" + str(sum(KeyWordAccLS)/len(KeyWordAccLS)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "U78gv02dszpC",
        "outputId": "ca1c8f58-3c60-4e4e-9346-0c0fd4380f9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [23:03, 13.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full list: [0.0, 0.0, 0.06350006350009525, 0.16116459280507606, 0.39223227027636803, 0.28603877677367767, 0.0, 0.3227486121839514, 0.629940788348712, 0.0, 0.22360679774997896, 0.30151134457776363, 0.0, 0.0, 0.4036036763977875, 0.75, 0.0, 0.29999999999999993, 0.4811252243246881, 0.0, 0.0, 0.0, 0.3768891807222045, 0.0, 0.0, 0.33407655239053047, 0.0, 0.9999999999999998, 0.6666666666666667, 0.0, 0.2357022603955158, 0.0, 0.0, 0.0, 0.0, 0.06900655593423542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15811388300841897, 0.0, 0.11180339887498948, 0.0, 0.10540925533894598, 0.3442651863295481, 0.14142135623730948, 0.5017452060042545, 0.4714045207910316, 0.1025978352085154, 0.21081851067789195, 0.28867513459481287, 0.4216370213557839, 0.0, 0.11396057645963795, 0.45643546458763845, 0.13801311186847084, 0.7999999999999998, 0.35007002100700246, 0.5477225575051661, 0.30618621784789724, 0.09999999999999998, 0.5809475019311126, 0.12403473458920847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35355339059327373, 0.0, 0.12499999999999997, 0.0, 0.2004459314343183, 0.33333333333333337, 0.0, 0.2279211529192759, 0.5773502691896258, 0.15811388300841897, 0.5853694070049636, 0.5833333333333334, 0.33333333333333337, 0.0, 0.2182178902359924, 0.26726124191242434, 0.0, 0.0, 0.2182178902359924, 0.18257418583505536, 0.0, 0.0, 0.33333333333333337, 0.13363062095621217]\n",
            "The norwegian average accuracy: 0.18204064053923766\n",
            "The norwegian keyword spotting accuracy: 0.14280062432220428\n",
            "Full list LS: [0.16666666666666669, 0.4472135954999579, 0.40089186286863654, 0.3481553119113957, 0.41812100500354543, 0.28603877677367767, 0.2886751345948129, 0.3227486121839514, 0.629940788348712, 0.0, 0.22360679774997896, 0.30151134457776363, 0.4767312946227962, 0.16666666666666669, 0.4003203845127179, 0.75, 0.5999999999999999, 0.29999999999999993, 0.4811252243246881, 0.5, 0.0, 0.0, 0.3768891807222045, 0.5773502691896258, 0.0, 0.33407655239053047, 0.37499999999999994, 0.9999999999999998, 0.5000000000000001, 0.09128709291752768, 0.2357022603955158, 0.31980107453341566, 0.09534625892455924, 0.0, 0.2581988897471611, 0.24174688920761409, 0.17407765595569785, 0.1543033499620919, 0.08333333333333334, 0.0, 0.26726124191242434, 0.26906911759852503, 0.13363062095621217, 0.0, 0.0, 0.15811388300841897, 0.2357022603955158, 0.09999999999999998, 0.0608862565547983, 0.1111111111111111, 0.6708203932499369, 0.5999999999999999, 0.5017452060042545, 0.4714045207910316, 0.35856858280031806, 0.38138503569823695, 0.33333333333333337, 0.4216370213557839, 0.5000000000000001, 0.46709936649691375, 0.45643546458763845, 0.13801311186847084, 0.19999999999999996, 0.35007002100700246, 0.5477225575051661, 0.49029033784546, 0.09999999999999998, 0.5809475019311126, 0.15811388300841897, 0.0, 0.0, 0.33806170189140655, 0.5, 0.23570226039551587, 0.6708203932499369, 0.3086066999241838, 0.35355339059327373, 0.5714285714285714, 0.24999999999999994, 0.6666666666666667, 0.6681531047810609, 0.33333333333333337, 0.25, 0.5222329678670935, 1.0, 0.6149186938124421, 0.6363636363636364, 0.5833333333333334, 0.33333333333333337, 0.33333333333333337, 0.4285714285714285, 0.5714285714285714, 0.0, 0.3651483716701107, 0.26726124191242434, 0.5999999999999999, 0.33333333333333337, 0.2519763153394848, 0.6666666666666667, 0.13363062095621217]\n",
            "The norwegian average accuracy LS: 0.3417674507279068\n",
            "The norwegian keyword spotting accuracy LS: 0.26052295168838524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Establish baseline with Norwegian test\n",
        "#loading in the dataset tsv\n",
        "dataNorwegian = pd.read_csv(\"/content/drive/MyDrive/CommonVoiceMitch/Norwegian/nn-NO/validated.tsv\", sep=\"\\t\")\n",
        "AccList = []\n",
        "AccListLS = []\n",
        "KeyWordAcc = []\n",
        "KeyWordAccLS = []\n",
        "i = 0\n",
        "\n",
        "for samp in tqdm(dataNorwegian.iterrows()):\n",
        "  if i == LIMIT:\n",
        "    break\n",
        "  file_path = \"/content/drive/MyDrive/CommonVoiceMitch/Norwegian/nn-NO/clips/\"+samp[1][1]\n",
        "  pred = transcribe(model, file_path)\n",
        "  predLS = transcribeLS(model, file_path, \"no\")\n",
        "  text = samp[1][2]\n",
        "  AccList.append(get_cosinesimularity(pred,text))\n",
        "  AccListLS.append(get_cosinesimularity(predLS,text))\n",
        "  KeyWordAcc.append(get_cosinesimularity(grab_keywords(pred ,5), grab_keywords(text, 5)))\n",
        "  KeyWordAccLS.append(get_cosinesimularity(grab_keywords(predLS ,5), grab_keywords(text, 5)))\n",
        "  i = i + 1\n",
        "Average = sum(AccList) / len(AccList)\n",
        "print(\"Full list: \" + str(AccList))\n",
        "print(\"The norwegian average accuracy: \" + str(Average))\n",
        "print(\"The norwegian keyword spotting accuracy: \" + str(sum(KeyWordAcc)/len(KeyWordAcc)))\n",
        "\n",
        "AverageLS = sum(AccListLS) / len(AccListLS)\n",
        "print(\"Full list LS: \" + str(AccListLS))\n",
        "print(\"The norwegian average accuracy LS: \" + str(AverageLS))\n",
        "print(\"The norwegian keyword spotting accuracy LS: \" + str(sum(KeyWordAccLS)/len(KeyWordAccLS)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GCGb4U-itcgq",
        "outputId": "69cf0202-c2c0-494f-a13a-0e0cc76a5731"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [22:09, 13.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full list: [0.0, 0.0, 0.4714045207910316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999996, 0.0, 0.0, 0.0, 0.0, 0.40824829046386296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.40824829046386296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2886751345948129, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2886751345948129, 0.33333333333333337, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.6324555320336759, 0.0]\n",
            "The serbian average accuracy: 0.042750571721316855\n",
            "The serbian keyword spotting accuracy: 0.015477225575051662\n",
            "Full list LS: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "The serbian average accuracy LS: 0.0\n",
            "The serbian keyword spotting accuracy LS: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Establish baseline with Serbian test\n",
        "#loading in the dataset tsv\n",
        "dataSerbian = pd.read_csv(\"/content/drive/MyDrive/CommonVoiceMitch/Serbian/sr/validated.tsv\", sep=\"\\t\")\n",
        "AccList = []\n",
        "AccListLS = []\n",
        "KeyWordAcc = []\n",
        "KeyWordAccLS = []\n",
        "i = 0\n",
        "\n",
        "for samp in tqdm(dataSerbian.iterrows()):\n",
        "  if i == LIMIT:\n",
        "    break\n",
        "  file_path = \"/content/drive/MyDrive/CommonVoiceMitch/Serbian/sr/clips/\"+samp[1][1]\n",
        "  pred = transcribe(model, file_path)\n",
        "  predLS = transcribeLS(model, file_path, \"sr\")\n",
        "  text = samp[1][2]\n",
        "  AccList.append(get_cosinesimularity(pred,text))\n",
        "  AccListLS.append(get_cosinesimularity(predLS,text))\n",
        "  KeyWordAcc.append(get_cosinesimularity(grab_keywords(pred ,5), grab_keywords(text, 5)))\n",
        "  KeyWordAccLS.append(get_cosinesimularity(grab_keywords(predLS ,5), grab_keywords(text, 5)))\n",
        "  i = i + 1\n",
        "Average = sum(AccList) / len(AccList)\n",
        "print(\"Full list: \" + str(AccList))\n",
        "print(\"The serbian average accuracy: \" + str(Average))\n",
        "print(\"The serbian keyword spotting accuracy: \" + str(sum(KeyWordAcc)/len(KeyWordAcc)))\n",
        "\n",
        "AverageLS = sum(AccListLS) / len(AccListLS)\n",
        "print(\"Full list LS: \" + str(AccListLS))\n",
        "print(\"The serbian average accuracy LS: \" + str(AverageLS))\n",
        "print(\"The serbian keyword spotting accuracy LS: \" + str(sum(KeyWordAccLS)/len(KeyWordAccLS)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}